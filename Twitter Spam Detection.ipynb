{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8nguJbs0LSz"
      },
      "source": [
        "Web Crawler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f30SjBLzvHY_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "from getpass import getpass\n",
        "from time import sleep\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from msedge.selenium_tools import Edge, EdgeOptions\n",
        "\n",
        "def get_tweet_data(card):\n",
        "    \"\"\"Extract data from tweet card\"\"\"\n",
        "    username = card.find_element(\"xpath\",'.//span').text\n",
        "    try:\n",
        "        handle = card.find_element(\"xpath\",'.//span[contains(text(), \"@\")]').text\n",
        "    except NoSuchElementException:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        postdate = card.find_element(\"xpath\",'.//time').get_attribute('datetime')\n",
        "    except NoSuchElementException:\n",
        "        return\n",
        "\n",
        "    comment = card.find_element(\"xpath\",'.//div[2]/div[2]/div[1]').text\n",
        "    responding = card.find_element(\"xpath\",'.//div[2]/div[2]/div[2]').text\n",
        "    text = comment + responding\n",
        "    reply_cnt = card.find_element(\"xpath\",'.//div[@data-testid=\"reply\"]').text\n",
        "    retweet_cnt = card.find_element(\"xpath\",'.//div[@data-testid=\"retweet\"]').text\n",
        "    like_cnt = card.find_element(\"xpath\",'.//div[@data-testid=\"like\"]').text\n",
        "\n",
        "    # get a string of all emojis contained in the tweet\n",
        "    \"\"\"Emojis are stored as images... so I convert the filename, which is stored as unicode, into\n",
        "    the emoji character.\"\"\"\n",
        "    emoji_tags = card.find_elements(\"xpath\",'.//img[contains(@src, \"emoji\")]')\n",
        "    emoji_list = []\n",
        "    for tag in emoji_tags:\n",
        "        filename = tag.get_attribute('src')\n",
        "        try:\n",
        "            emoji = chr(int(re.search(r'svg\\/([a-z0-9]+)\\.svg', filename).group(1), base=16))\n",
        "        except AttributeError:\n",
        "            continue\n",
        "        if emoji:\n",
        "            emoji_list.append(emoji)\n",
        "    emojis = ' '.join(emoji_list)\n",
        "\n",
        "    tweet = (username, handle, postdate, text, emojis, reply_cnt, retweet_cnt, like_cnt)\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "5F0hPqc5w1oj",
        "outputId": "0552d6d1-a9bb-46cf-ee39-d37b29a48bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "username: VateamK\n",
            "Password: Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "search term: #CSKvsRR\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kldat\\AppData\\Local\\Temp\\ipykernel_16340\\2738353507.py:10: DeprecationWarning: Selenium Tools for Microsoft Edge is deprecated. Please upgrade to Selenium 4 which has built-in support for Microsoft Edge (Chromium): https://docs.microsoft.com/en-us/microsoft-edge/webdriver-chromium/#upgrading-from-selenium-3\n",
            "  driver = Edge(options=options)\n"
          ]
        }
      ],
      "source": [
        "# application variables\n",
        "user = input('username: ')\n",
        "my_password = getpass('Password: ')\n",
        "search_term = input('search term: ')\n",
        "\n",
        "\n",
        "# create instance of web driver\n",
        "options = EdgeOptions()\n",
        "options.use_chromium = True\n",
        "driver = Edge(options=options)\n",
        "\n",
        "# navigate to login screen\n",
        "driver.get('https://www.twitter.com/login')\n",
        "driver.maximize_window()\n",
        "sleep(5)\n",
        "username = driver.find_element(\"xpath\",'//input[@name=\"text\"]')\n",
        "username.send_keys(user)\n",
        "username.send_keys(Keys.RETURN)\n",
        "sleep(3)\n",
        "\n",
        "password = driver.find_element('xpath','//input[@name=\"password\"]')\n",
        "password.send_keys(my_password)\n",
        "password.send_keys(Keys.RETURN)\n",
        "sleep(3)\n",
        "\n",
        "# find search input and search for term\n",
        "search_input = driver.find_element('xpath','//input[@aria-label=\"Search query\"]')\n",
        "search_input.send_keys(search_term)\n",
        "search_input.send_keys(Keys.RETURN)\n",
        "sleep(1)\n",
        "\n",
        "# navigate to historical 'latest' tab\n",
        "driver.find_element(\"link text\",'Latest').click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RID4FY6ew1lK"
      },
      "outputs": [],
      "source": [
        "# get all tweets on the page\n",
        "data = []\n",
        "twitter_tweet_ = []\n",
        "tweet_ids = set()\n",
        "last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
        "scrolling = True\n",
        "\n",
        "while scrolling:\n",
        "    page_cards = driver.find_elements('xpath', '//article[@data-testid=\"tweet\"]')\n",
        "    for card in page_cards[-15:]:\n",
        "        tweet = get_tweet_data(card)\n",
        "        if tweet:\n",
        "            tweet_id = ''.join(tweet)\n",
        "            if tweet_id not in tweet_ids:\n",
        "                tweet_ids.add(tweet_id)\n",
        "                data.append(tweet)\n",
        "                twitter_tweet_.append(tweet[3])\n",
        "\n",
        "    scroll_attempt = 0\n",
        "    while True:\n",
        "        # check scroll position\n",
        "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
        "        sleep(2)\n",
        "        curr_position = driver.execute_script(\"return window.pageYOffset;\")\n",
        "        if last_position == curr_position:\n",
        "            scroll_attempt += 1\n",
        "\n",
        "            # end of scroll region\n",
        "            if scroll_attempt >= 3:\n",
        "                scrolling = False\n",
        "                break\n",
        "            else:\n",
        "                sleep(2) # attempt another scroll\n",
        "        else:\n",
        "            last_position = curr_position\n",
        "            break\n",
        "\n",
        "# close the web driver\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPus1fwcw1jI"
      },
      "outputs": [],
      "source": [
        "with open('ProjectK.csv', 'w', newline='', encoding='utf-8') as f:\n",
        "    header = ['UserName', 'Handle', 'Timestamp', 'Text', 'Emojis', 'Comments', 'Likes', 'Retweets']\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jut64ekTw1c1",
        "outputId": "f4dc8ffa-87fa-45e7-970c-1513fbf648ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Text</th>\n",
              "      <th>Emojis</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢</td>\n",
              "      <td>@SaiPrav26957591</td>\n",
              "      <td>2023-04-13T07:51:05.000Z</td>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\\n@SaiPrav26957591\\nÂ·\\n5m\"KARMA\" ...</td>\n",
              "      <td>ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rozana Spokesman</td>\n",
              "      <td>@RozanaSpokesman</td>\n",
              "      <td>2023-04-13T07:50:34.000Z</td>\n",
              "      <td>Rozana Spokesman\\n@RozanaSpokesman\\nÂ·\\n6m#IPL2...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Broadcast Media</td>\n",
              "      <td>@vijendra_deepa</td>\n",
              "      <td>2023-04-13T07:50:11.000Z</td>\n",
              "      <td>Broadcast Media\\n@vijendra_deepa\\nÂ·\\n6mThe uni...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venky_K</td>\n",
              "      <td>@VenkyK_Offic</td>\n",
              "      <td>2023-04-13T07:49:37.000Z</td>\n",
              "      <td>Venky_K\\n@VenkyK_Offic\\nÂ·\\n6mBeautiful Video.....</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albin Prince</td>\n",
              "      <td>@prinz_albin</td>\n",
              "      <td>2023-04-13T07:48:57.000Z</td>\n",
              "      <td>Albin Prince\\n@prinz_albin\\nÂ·\\n7mMy Man \\n@msd...</td>\n",
              "      <td>ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           UserName            Handle                 Timestamp  \\\n",
              "0     _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢  @SaiPrav26957591  2023-04-13T07:51:05.000Z   \n",
              "1  Rozana Spokesman  @RozanaSpokesman  2023-04-13T07:50:34.000Z   \n",
              "2   Broadcast Media   @vijendra_deepa  2023-04-13T07:50:11.000Z   \n",
              "3           Venky_K     @VenkyK_Offic  2023-04-13T07:49:37.000Z   \n",
              "4      Albin Prince      @prinz_albin  2023-04-13T07:48:57.000Z   \n",
              "\n",
              "                                                Text               Emojis  \\\n",
              "0  _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\\n@SaiPrav26957591\\nÂ·\\n5m\"KARMA\" ...  ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©   \n",
              "1  Rozana Spokesman\\n@RozanaSpokesman\\nÂ·\\n6m#IPL2...                        \n",
              "2  Broadcast Media\\n@vijendra_deepa\\nÂ·\\n6mThe uni...                        \n",
              "3  Venky_K\\n@VenkyK_Offic\\nÂ·\\n6mBeautiful Video.....                        \n",
              "4  Albin Prince\\n@prinz_albin\\nÂ·\\n7mMy Man \\n@msd...    ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯   \n",
              "\n",
              "  Comments Likes Retweets  \n",
              "0                          \n",
              "1                          \n",
              "2                          \n",
              "3                          \n",
              "4                       2  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "header = ['UserName', 'Handle', 'Timestamp', 'Text', 'Emojis', 'Comments', 'Likes', 'Retweets']\n",
        "df = pd.DataFrame(data,columns= header)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRYue0gdw1Z0"
      },
      "outputs": [],
      "source": [
        "twitter_tweet = pd.array(twitter_tweet_)\n",
        "df['Text'] = twitter_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7MDx4Now1YA",
        "outputId": "07ab246b-722c-4fa2-b058-5efa2b920ade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Ruchita Jain #savesoil',\n",
              " '@Ruchitaamehtaa',\n",
              " '2023-04-13T06:54:25.000Z',\n",
              " 'Ruchita Jain #savesoil\\n@Ruchitaamehtaa\\nÂ·\\n1hNamaskaram #MSDhoni #ChennaiSuperKings #CSKvsRR #ishafoundation #ishayoga #sadhguru #IshaFoundation #Sadhguru \\n@ishafoundation',\n",
              " 'ğŸ™ ğŸŒ¸ ğŸ™Œ',\n",
              " '',\n",
              " '',\n",
              " '1')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dFkXWeZw1WC",
        "outputId": "c4c0deac-9e6c-4128-d37c-9b9a4aaa0a8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<StringArray>\n",
              "[                                                                                                                                                                    '_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\\n@SaiPrav26957591\\nÂ·\\n5m\"KARMA\" is Boomerang  \\n\\nCSGay fans crying is my source of happiness.  Their tears work as glucose for my body, their screams bring peace to my ears. \\n\\nBest Scenery of this IPL \\n\\n#CSKvsRR',\n",
              "                                                                                                                                                                                                                                                                        'Rozana Spokesman\\n@RozanaSpokesman\\nÂ·\\n6m#IPL2023: #RajasthanRoyals beat #ChennaiSuperKings by 3 runs \\n\\n#CSKvsRR #RRvsCSK #IPLT20',\n",
              "                                                                                                          \"Broadcast Media\\n@vijendra_deepa\\nÂ·\\n6mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n\\n#SoppanaSundariFrom14April \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n @proyuvraaj\",\n",
              "                                                                                                                                                                                                                                                                                                   'Venky_K\\n@VenkyK_Offic\\nÂ·\\n6mBeautiful Video.. Dad Little Princess \\n\\n #SandeepSharma #CSKvsRR #MSDhoni',\n",
              "                                                                                                                        \"Albin Prince\\n@prinz_albin\\nÂ·\\n7mMy Man \\n@msdhoni\\n is playing with pain for us \\n\\nThe Man The Myth The Legend \\n\\nI'll be with him, always a #Thala fan\\n\\n#ThalaDhoni  #MSDhoniğ“ƒµ #CSKvsRR #ChennaiSuperKingsvsRajasthanRoyals #ChennaiSuperKings #CSK #GOAT #CSKvsRCB #SK21 #SK\",\n",
              "                                                                                                                                                                                                                                                        'Arman Malik\\n@Armanmalik9582\\nÂ·\\n8mMost Wins vs CSK at Chepauk\\n\\n5 - MI\\n2 - RR*\\n2 - DC\\n2 - KKR\\n2 - PBKS\\n2 - DEC\\n1 - PWI\\n1 - RCB\\n\\n#CSKvsRR',\n",
              "                                                                                                                                                                                                                                           'Monu Bhagwat\\n@imonubhagwat\\nÂ·\\n9mMahendra singh dhoni will always be the best finisher ever..\\n2.2 Cr viewvership ...mahi craze#CSKvsRR #RRvsCSK #MSDhoniğ“ƒµ #MSD',\n",
              "                                                                                                                                                                                 \"HT Sports\\n@HTSportsNews\\nÂ·\\n18mR Ashwin reacted to the umpires changing the ball for dew on their own. He also revealed that as a bowling team RR didn't ask for the ball to be changed\\n\\n#IPL #IPL2023 #CSKvsRR #CSKvRR\",\n",
              "                                                                                                                                                            'Kanak News\\n@kanak_news\\nÂ·\\n18mà¬¨à¬¿à¬²à¬¾à¬®à¬°à­‡ à¬¥à¬¿à¬²à­‡ à¬…à¬¨à¬¸à­‹à¬²à­à¬¡ à¥¤ à¬¬à¬¦à¬³ à¬–à­‡à¬³à¬¾à¬³à­€ à¬­à¬¾à¬¬à­‡ à¬¸à¬¾à¬®à¬¿à¬² à¬¹à­‡à¬²à­‡, à¬®à¬¾à¬¹à¬¿à¬™à­à¬•à­ à¬®à¬¾à¬¤à­ à¬¦à­‡à¬‡ à¬°à¬¾à¬œà¬¸à­à¬¥à¬¾à¬¨à¬•à­ à¬¬à¬¿à¬œà­Ÿ à¬­à­‡à¬Ÿà¬¿ à¬¦à­‡à¬²à­‡ à¥¤ #KanakNews \\n@IPL\\n  #Cricket #CSKvsRR \\nhttps://kanaknews.com/sandeep-sharma-wins-heart-after-rajasthans-win/â€¦',\n",
              "                                                                                                                                                                                                                                                                                                                          'Jashpal Machhar\\n@jashpal_machhar\\nÂ·\\n18mMahendra Singh dhoni\\n#MSDhoniğ“ƒµ #CSKvsRR',\n",
              "                                                                                         'FilmyDude\\n@ItsFilmyDude\\nÂ·\\n18mhttps://filmydude.com/bhediya2-a-new-horror-comedy-film/â€¦\\n#Bhediya2 : A New Horror-Comedy Film\\n\\n#VarunDhawan is back...  The release date of Stree 2 and Bhediya 2 has been announced in 2025.  Congratulations India #Bhediya2 #VarunDhawan #Stree2 #TejRan #CSKvsRR #wtcfinal',\n",
              "                                                                                                                                                                                                                                                                                          \"Crickaith\\n@Crickaith\\nÂ·\\n19m#MSDhoni got emotional after seeing his first love's look-alike in #CSKvsRR #IPL2023\",\n",
              "                                                                                                                                                  'Mooha Swartz\\n@CyberAnonymous\\nÂ·\\n19mtimesofindia: RT \\n@toisports\\n: How vintage Dhoni rolled back the clock, but Rajasthan Royals still managed to beat CSK\\n\\nSTORY IN IMAGES: https://bit.ly/3GAIgGM\\n\\n#MSDhoni #CSKvsRR #IPL2023 #ChennaiSuperKings',\n",
              "                                                                                          \"Kollywood Scope - Tamil Cinema\\n@KollywoodScope\\nÂ·\\n20mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n\\n#SoppanaSundariFrom14April \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n @proyuvraaj\",\n",
              "                                                                                                                                                                                                                                                                           'Wisden India\\n@WisdenIndia\\nÂ·\\n27m41-year-old MS Dhoni is still going strong in IPL \\n\\n#MSDhoni #CSK #CSKvsRR #IPL2023 #Cricket',\n",
              "                                                       'Cricreads\\n@cricreads\\nÂ·\\n28mâ€˜I can hit it for a sixâ€¦â€™: Dhoni reveals incidents from Sandeepâ€™s last over https://cricreads.com/i-can-hit-it-for-a-six-dhoni-reveals-incidents-from-sandeeps-last-over/â€¦ via \\n@Cricreads\\n#MSDhoni #RaviShastri #SandeepSharma #ChennaiSuperKings #RajasthanRoyals #WhistlePodu #HallaBol #TATAIPL #CSKvsRR #RRvsCSK',\n",
              "                                                                                    \"Srivathsan\\n@ImSrivathsanS\\nÂ·\\n28m#RCB would have lost yesterday's match !! Any RCB bowler would have given away that last ball 6 !! RCB needs to dismantle their team and start from beginning. First get rid of the  management which thinks Harshal Patel can be our death bowler at Chinnaswamy !! #CSKvRR #CSKvsRR\",\n",
              "                                                                                    'LALIT PAWAR\\n@LALITPA66496881\\nÂ·\\n29mDream transforms into thoughts, thoughts results into action ///////\\n#SaturdayVibes  #AlluArjunğ“ƒµ #ShehnaazGill #Pushpa2TheRule #YaliCapkini #YemiCregx #weareoneEXO #AgustD #Pushpa2 #Pushpa #SUGA #Nil #ProudOfYouDidi #KolkataMetro #DeepikaPadukone #Bhediya2 #Stree2 #CSKvsRR',\n",
              "                                                                                                                                                                                                                                                  'Thanthi TV\\n@ThanthiTV\\nÂ·\\n30m\"à®¤à¯‹à®©à®¿à®•à¯à®•à¯ à®•à®¾à®¯à®®à¯.. à®®à¯à®•à¯à®•à®¿à®¯ à®µà¯€à®°à®°à¯ 3 à®®à¯‡à®Ÿà¯à®šà¯ à®†à®Ÿ à®®à®¾à®Ÿà¯à®Ÿà®¾à®°à¯\" - CSK à®°à®šà®¿à®•à®°à¯à®•à®³à¯à®•à¯à®•à¯ à®…à®¤à®¿à®°à¯à®šà¯à®šà®¿ à®¤à®•à®µà®²à¯\\n\\n#csk #ipl2023 #magala #cskvsrr',\n",
              "                                                                                                                                                                                                                                                                                                     'Yaar Paatha Vela Da Ithu\\n@YPVDI_Page\\nÂ·\\n30m after the Yesterday match  #CSKvsRR\\n\\n#CSKians #Paltans',\n",
              "                                                                                                                            \"INSubcontinent News\\n@INPrimeMinister\\nÂ·\\n31mB'luru man objects to dogs pooping in front of house, murdered - Follow/RT/Fav - : #NatureLovers : #INTERNATIONALJATDAY : #JallianwalaBaghMassacre : #CSKvsRR : Nature Campaign : : : #GodMorningThursday : sab gazab by badshah :\",\n",
              "                                                                                                                                                                                                             'Jaya Plus\\n@jayapluschannel\\nÂ·\\n31mà®šà¯†à®©à¯à®©à¯ˆ à®šà¯‡à®ªà¯à®ªà®¾à®•à¯à®•à®®à¯ à®®à¯ˆà®¤à®¾à®©à®¤à¯à®¤à®¿à®²à¯ CSK - RR à®ªà¯‹à®Ÿà¯à®Ÿà®¿à®¯à¯ˆ à®¨à¯‡à®°à®¿à®²à¯ à®•à®£à¯à®Ÿà¯à®•à®³à®¿à®¤à¯à®¤ à®¨à®Ÿà®¿à®•à¯ˆ à®ªà®¿à®¨à¯à®¤à¯à®®à®¾à®¤à®µà®¿!\\n@thebindumadhavi\\n #Chepaukstadium #CSKvsRR #Bindumadhavi #JayaPlus',\n",
              "                                                                             'Sports Tak\\n@sports_tak\\nÂ·\\n38mCSK vs RR: à¤§à¥‹à¤¨à¥€ à¤•à¥‡ à¤—à¤¢à¤¼ à¤®à¥‡à¤‚ à¤¹à¤²à¥à¤²à¤¾ à¤¬à¥‹à¤², 15 à¤¸à¤¾à¤² à¤¬à¤¾à¤¦ à¤šà¥‡à¤¨à¥à¤¨à¤ˆ à¤®à¥‡à¤‚ à¤œà¥€à¤¤à¤¾ à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨, à¤šà¥‡à¤ªà¥‰à¤• à¤•à¥‡ à¤¯à¥‡ à¤†à¤‚à¤•à¤¡à¤¼à¥‡ à¤¹à¥ˆà¤°à¤¾à¤¨ à¤•à¤°à¤¨à¥‡ à¤µà¤¾à¤²à¥‡\\n@IPL\\n @ChennaiIPL\\n#IPL2023 #CSKvsRR\\nhttps://hindi.thesportstak.com/cricket-news/csk-vs-rr-ipl-2023-records-ms-dhoni-chennai-super-kings-record-rajasthan-royals-sanju-samsonâ€¦',\n",
              "                                                                                                                                                                                                                                                                 'Sportskeeda\\n@Sportskeeda\\nÂ·\\n38mRajasthan Royals have now won the most games against CSK since 2020 \\n\\n#CricketTwitter #IPL2023 #cskvsrr',\n",
              "                                                                                                                   \"Filmywood\\n@Filmy_Wood\\nÂ·\\n39mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n\\n#SoppanaSundariFrom14April \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n @proyuvraaj\",\n",
              "                                                                                                              'Fantasy11\\n@Dream11Guruji\\nÂ·\\n40mWon Huge Last Night in #CskvsRR .\\nGreat Match...Happy to See Msd with Great Knock ...If you Also Want to br Part Of My Winnings....You can join Us on telegram:-https://t.me/+Rn_P7MDmY2IAVslwâ€¦\\nOr Whatsapp us on 9122906061 \\n#csk #RR #GTvsPBKS #dream11',\n",
              "                                                                                                                                                                                                                                                                         \"Zee News\\n@ZeeNews\\nÂ·\\n40m'à¤®à¥ˆà¤‚ à¤¹à¥ˆà¤°à¤¾à¤¨ à¤¹à¥‚à¤‚', à¤…à¤¶à¥à¤µà¤¿à¤¨ à¤¨à¥‡ à¤…à¤‚à¤ªà¤¾à¤¯à¤° à¤ªà¤° à¤²à¤—à¤¾à¤ à¤¯à¥‡ à¤—à¤‚à¤­à¥€à¤° à¤†à¤°à¥‹à¤ª; IPL à¤®à¥‡à¤‚ à¤ªà¥ˆà¤¦à¤¾ à¤¹à¥à¤† à¤¨à¤¯à¤¾ à¤µà¤¿à¤µà¤¾à¤¦\\n\\n#IPL2023 #CSKvsRR\",\n",
              "                                                                                           \"Pratyush Garg\\n@GargPratyush27\\nÂ·\\n40mA record 2.3 Crore accounts on Jio Cinema were watching the last over of yesterday's match when Mentor Singh Dhoni was at the crease. In the current Indian list of players, only he could have managed this level of viewership. Thala for a reason.\\n\\n#CSKvsRR #IPL2023\",\n",
              "                                                                                                                                                                                                                                  'The CRITIQUE\\n@PrinceAvmk1\\nÂ·\\n41mMy tweet before match , As expected pure talent show  #SanjuSamson Captaincy #MSDhoniğ“ƒµ Falt shots  #CSKvsRR Masssss Entertaining Match ',\n",
              "                         \"Hamsini Entertainment\\n@Hamsinient\\nÂ·\\n51mOur #SoppanaSundari team  promoted the film at the #CSKvsRR match at Chepauk last night..\\n\\nDon't miss this laugh riot in theaters.. Bookings Open now  https://in.bookmyshow.com/chennai/movies/soppana-sundari/ET00355707â€¦ \\n\\n#SoppanaSundariFrom14April \\n@aishu_dil\\n @SGCharles2\\n @LakshmiPriyaaC\\n @vivek4kr\\n @Mani_Rajeshh\\nâ€¦\",\n",
              "                                                                                                                                                                                                 'TamilaninCinema\\n@TamilaninCinema\\nÂ·\\n51mTeam #SoppanaSundari Promoted The Film At #CSKvsRR Match At Chepauk Last Night\\n\\n#SoppanaSundariFrom14April  ! \\n@aishu_dil\\n @Hamsinient\\n !  \\n@proyuvraaj\\n !',\n",
              "                                                                                                                                                                                                                    'amit bishnoi\\n@ImAmitBishnoi\\nÂ·\\n51m#MSDhoni Smashes 2 Sixes in Final Over but Sandeep Sharma did not allow MS Dhoni and Ravindra Jadeja to reach the target. #RajasthanRoyals #CSKvsRR',\n",
              " 'Sandesh\\n@sandeshnews\\nÂ·\\n51mCSK àª¸àª¾àª®à«‡àª¨à«€ àªœà«€àª¤ àª¬àª¾àª¦ àªªàª£ Sanju Samsonàª¨à«‡ àª«àªŸàª•àª¾àª°à«àª¯à«‹ àª¦àª‚àª¡, àª¤à«‹àª¡à«àª¯à«‹ ICCàª¨à«‹ àª† àª®àª¹àª¤à«àª¤à«àªµàª¨à«‹ àª¨àª¿àª¯àª®, àª«àª°à«€ àª†àªµà«àª‚ àª•àª°à«àª¯à«àª‚ àª¤à«‹ àª²àª¾àª—àª¶à«‡ àªªà«àª°àª¤àª¿àª¬àª‚àª§!\\n\\n#CSKvsRR #SanjuSamson #ICCCodeOFConduct  #ICCRules #SlowOverRate\\n\\nhttps://sandesh.com/sports/icc-fined-rajasthan-royals-captain-sanju-samson-rs-12-lakh-for-slow-over-rateâ€¦\\n\\nàªµàª§à« àª¸àª®àª¾àªšàª¾àª° àªµàª¾àª‚àªšàªµàª¾ àª¡àª¾àª‰àª¨àª²à«‹àª¡ àª•àª°à«‹ àª¸àª‚àª¦à«‡àª¶ àª¨à«àª¯à«‚àª àªàªª : https://sandesh.com/d',\n",
              "                                                                                                                                                                                                                                                               'ABP Ananda\\n@abpanandatv\\nÂ·\\n51mà¦°à¦¾à¦œà¦¸à§à¦¥à¦¾à¦¨ à¦®à§à¦¯à¦¾à¦šà§‡à¦° à¦ªà¦°à§‡à¦‡ à¦§à§‹à¦¨à¦¿à¦° à¦šà§‹à¦Ÿ à¦¨à¦¿à¦¯à¦¼à§‡ à¦®à§à¦–à§‡ à¦–à§‹à¦²à§‡à¦¨ à¦«à§à¦²à§‡à¦®à¦¿à¦‚\\n#IPL2023 #IPLT20 #MSDhoni #StephenFleming #CSKvsRR',\n",
              "                                                                                                                     'Crude & Nifty Daily View\\n@hemakaroonya1\\nÂ·\\n52m13/04 : \"Nifty\\'s Capital Protection Method \" \\n\\n ( catch 40 to 50 points ) \\n\\n 2ND CALL ; Nifty Sold at 17787\\n\\n  #Crude #WTI #Nifty #NiftyBank #niftyOptions #CrudeOil #crude #ThalapathyVijay #Yorker #MSDhoni #CSKvsRR #IPL2023',\n",
              "                                                                                                                                   \"Kolly Buzz\\n@KollyBuzz\\nÂ·\\n53mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n #SoppanaSundariFrom14April\",\n",
              "                                                                                                                                                                                                                                                          'Times Now Sports\\n@timesnowsports\\nÂ·\\n1h#MSDhoni #RavichandranAshwin #CSKvsRR\\n@msdhoni\\n almost pulled off yet another run-chase.\\n@ashwinravi99',\n",
              "                                                                                                                                                                                'Hindustan Times Marathi\\n@htmarathi\\nÂ·\\n1hCSK vs RR: à¤†à¤¯à¤ªà¥€à¤à¤² à¥¨à¥¦à¥¨à¥© à¤šà¥à¤¯à¤¾ à¥§à¥­à¤µà¥à¤¯à¤¾ à¤¸à¤¾à¤®à¤¨à¥à¤¯à¤¾à¤¤ à¤šà¥‡à¤¨à¥à¤¨à¤ˆ à¤¸à¥à¤ªà¤°à¤•à¤¿à¤‚à¤—à¥à¤œà¤šà¥à¤¯à¤¾ à¤¸à¤‚à¤˜à¤¾à¤²à¤¾ à¥© à¤§à¤¾à¤µà¤¾à¤‚à¤¨à¥€ à¤ªà¤°à¤¾à¤­à¤µ à¤¸à¥à¤µà¥€à¤•à¤¾à¤°à¤¾à¤µà¤¾ à¤²à¤¾à¤—à¤²à¤¾.\\n\\n#IPL #IPL2023 #CSKvsRR #ChennaiSuperKings #RajasthanRoyals #MSDhoni',\n",
              "                                                                          'Sumit Mukherjee\\n@Who_Sumit\\nÂ·\\n1hMost IPL matches as Captain for a Team\\n\\n200 - Dhoni for CSK\\n146 - Rohit for MI\\n140 - Kohli for RCB \\n108 - Gambhir for KKR\\n\\n#IPL2023 #CSKvsRR #CSKvRR #RRvsCSK #RRvCSK #MSDhoni #Yellove #RajasthanRoyals #PBKSvGT #SanjuSamson #JosButtler #SandeepSharma #GTvPBKS  #IndianPremierLeague',\n",
              "                                                                                                                                                                                                                                                                               'Akash Purohit\\n@earthtoakash\\nÂ·\\n1hà¤•à¤¾à¤² à¤°à¥‡ à¤®à¥ˆà¤š à¤®à¤¾à¤¯ RR à¤²à¤¾à¤‡à¤µ à¤°à¥€ à¤•à¥€ à¤à¤²à¤•à¤¿à¤¯à¤¾à¤à¥¤\\n#Royals #RR #CSKvsRR #à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨à¥€\\n\\n:- \\n@JioCinema',\n",
              "                                                                                                                                                                                                                              'Ruchita Jain #savesoil\\n@Ruchitaamehtaa\\nÂ·\\n1hNamaskaram #MSDhoni #ChennaiSuperKings #CSKvsRR #ishafoundation #ishayoga #sadhguru #IshaFoundation #Sadhguru \\n@ishafoundation']\n",
              "Length: 41, dtype: string"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2BRSzQJ0_h6",
        "outputId": "8da8d476-516f-4b84-de2a-97da1a455b27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Text</th>\n",
              "      <th>Emojis</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢</td>\n",
              "      <td>@SaiPrav26957591</td>\n",
              "      <td>2023-04-13T07:51:05.000Z</td>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\\n@SaiPrav26957591\\nÂ·\\n5m\"KARMA\" ...</td>\n",
              "      <td>ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rozana Spokesman</td>\n",
              "      <td>@RozanaSpokesman</td>\n",
              "      <td>2023-04-13T07:50:34.000Z</td>\n",
              "      <td>Rozana Spokesman\\n@RozanaSpokesman\\nÂ·\\n6m#IPL2...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Broadcast Media</td>\n",
              "      <td>@vijendra_deepa</td>\n",
              "      <td>2023-04-13T07:50:11.000Z</td>\n",
              "      <td>Broadcast Media\\n@vijendra_deepa\\nÂ·\\n6mThe uni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venky_K</td>\n",
              "      <td>@VenkyK_Offic</td>\n",
              "      <td>2023-04-13T07:49:37.000Z</td>\n",
              "      <td>Venky_K\\n@VenkyK_Offic\\nÂ·\\n6mBeautiful Video.....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albin Prince</td>\n",
              "      <td>@prinz_albin</td>\n",
              "      <td>2023-04-13T07:48:57.000Z</td>\n",
              "      <td>Albin Prince\\n@prinz_albin\\nÂ·\\n7mMy Man \\n@msd...</td>\n",
              "      <td>ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           UserName            Handle                 Timestamp  \\\n",
              "0     _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢  @SaiPrav26957591  2023-04-13T07:51:05.000Z   \n",
              "1  Rozana Spokesman  @RozanaSpokesman  2023-04-13T07:50:34.000Z   \n",
              "2   Broadcast Media   @vijendra_deepa  2023-04-13T07:50:11.000Z   \n",
              "3           Venky_K     @VenkyK_Offic  2023-04-13T07:49:37.000Z   \n",
              "4      Albin Prince      @prinz_albin  2023-04-13T07:48:57.000Z   \n",
              "\n",
              "                                                Text               Emojis  \\\n",
              "0  _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\\n@SaiPrav26957591\\nÂ·\\n5m\"KARMA\" ...  ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©   \n",
              "1  Rozana Spokesman\\n@RozanaSpokesman\\nÂ·\\n6m#IPL2...                  NaN   \n",
              "2  Broadcast Media\\n@vijendra_deepa\\nÂ·\\n6mThe uni...                  NaN   \n",
              "3  Venky_K\\n@VenkyK_Offic\\nÂ·\\n6mBeautiful Video.....                  NaN   \n",
              "4  Albin Prince\\n@prinz_albin\\nÂ·\\n7mMy Man \\n@msd...    ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯   \n",
              "\n",
              "   Comments  Likes  Retweets  \n",
              "0       NaN    NaN       NaN  \n",
              "1       NaN    NaN       NaN  \n",
              "2       NaN    NaN       NaN  \n",
              "3       NaN    NaN       NaN  \n",
              "4       NaN    NaN       2.0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Read the CSV file into a DataFrame\n",
        "MYdata = pd.read_csv('ProjectK.csv')\n",
        "\n",
        "# Print the DataFrame\n",
        "MYdata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKJXuTcV0_fi",
        "outputId": "ad072b39-77fa-4bdb-a7f2-42bfb667b93b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Text</th>\n",
              "      <th>Emojis</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢</td>\n",
              "      <td>@SaiPrav26957591</td>\n",
              "      <td>2023-04-13T07:51:05.000Z</td>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\n",
              "@SaiPrav26957591\n",
              "Â·\n",
              "5m\"KARMA\" is ...</td>\n",
              "      <td>ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rozana Spokesman</td>\n",
              "      <td>@RozanaSpokesman</td>\n",
              "      <td>2023-04-13T07:50:34.000Z</td>\n",
              "      <td>Rozana Spokesman\n",
              "@RozanaSpokesman\n",
              "Â·\n",
              "6m#IPL2023...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Broadcast Media</td>\n",
              "      <td>@vijendra_deepa</td>\n",
              "      <td>2023-04-13T07:50:11.000Z</td>\n",
              "      <td>Broadcast Media\n",
              "@vijendra_deepa\n",
              "Â·\n",
              "6mThe unit o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venky_K</td>\n",
              "      <td>@VenkyK_Offic</td>\n",
              "      <td>2023-04-13T07:49:37.000Z</td>\n",
              "      <td>Venky_K\n",
              "@VenkyK_Offic\n",
              "Â·\n",
              "6mBeautiful Video.. Da...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albin Prince</td>\n",
              "      <td>@prinz_albin</td>\n",
              "      <td>2023-04-13T07:48:57.000Z</td>\n",
              "      <td>Albin Prince\n",
              "@prinz_albin\n",
              "Â·\n",
              "7mMy Man \n",
              "@msdhoni...</td>\n",
              "      <td>ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           UserName            Handle                 Timestamp  \\\n",
              "0     _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢  @SaiPrav26957591  2023-04-13T07:51:05.000Z   \n",
              "1  Rozana Spokesman  @RozanaSpokesman  2023-04-13T07:50:34.000Z   \n",
              "2   Broadcast Media   @vijendra_deepa  2023-04-13T07:50:11.000Z   \n",
              "3           Venky_K     @VenkyK_Offic  2023-04-13T07:49:37.000Z   \n",
              "4      Albin Prince      @prinz_albin  2023-04-13T07:48:57.000Z   \n",
              "\n",
              "                                                Text               Emojis  \\\n",
              "0  _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\n",
              "@SaiPrav26957591\n",
              "Â·\n",
              "5m\"KARMA\" is ...  ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©   \n",
              "1  Rozana Spokesman\n",
              "@RozanaSpokesman\n",
              "Â·\n",
              "6m#IPL2023...                  NaN   \n",
              "2  Broadcast Media\n",
              "@vijendra_deepa\n",
              "Â·\n",
              "6mThe unit o...                  NaN   \n",
              "3  Venky_K\n",
              "@VenkyK_Offic\n",
              "Â·\n",
              "6mBeautiful Video.. Da...                  NaN   \n",
              "4  Albin Prince\n",
              "@prinz_albin\n",
              "Â·\n",
              "7mMy Man \n",
              "@msdhoni...    ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯   \n",
              "\n",
              "   Comments  Likes  Retweets  \n",
              "0       NaN    NaN       NaN  \n",
              "1       NaN    NaN       NaN  \n",
              "2       NaN    NaN       NaN  \n",
              "3       NaN    NaN       NaN  \n",
              "4       NaN    NaN       2.0  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MYdata['Text'] = twitter_tweet\n",
        "MYdata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztFBF74e13Pr"
      },
      "source": [
        "Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdmMw_ht0_db"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dDIOzZ6t1LWR",
        "outputId": "930b6ce8-7e20-4548-939e-4f59231a1265"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfgHFUTolkXj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r'C:\\Users\\kldat\\Downloads\\spam_ham.csv', encoding=\"ISO-8859-1\").iloc[:, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nozWYFvBArP6"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns={'v1': 'Type', 'v2': 'Tweet'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L4pRY1aOBOt2",
        "outputId": "2c3b5022-54bd-48f7-ae09-56be134721e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Type\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwf0ryH72CMD"
      },
      "source": [
        "Remove Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bXt-3_hM1Ll4",
        "outputId": "f41f7ae1-e3cb-46cb-8a92-bd2930408ac4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Type  \\\n",
              "0  Go until jurong point, crazy.. Available only ...   ham   \n",
              "1                      Ok lar... Joking wif u oni...   ham   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam   \n",
              "3  U dun say so early hor... U c already then say...   ham   \n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham   \n",
              "\n",
              "                                     body_text_clean  \n",
              "0  Go until jurong point crazy Available only in ...  \n",
              "1                            Ok lar Joking wif u oni  \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  \n",
              "3        U dun say so early hor U c already then say  \n",
              "4  Nah I dont think he goes to usf he lives aroun...  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to remove punctuations.\n",
        "def remove_punc(text):\n",
        "    nonP_text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return nonP_text\n",
        "\n",
        "df[\"body_text_clean\"] = df[\"Tweet\"].apply(lambda x: remove_punc(x))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ekHpf8IW1Lr6",
        "outputId": "24943f31-c302-4919-9034-c4ea66d703e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Type  \\\n",
              "0  Go until jurong point, crazy.. Available only ...   ham   \n",
              "1                      Ok lar... Joking wif u oni...   ham   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam   \n",
              "3  U dun say so early hor... U c already then say...   ham   \n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham   \n",
              "\n",
              "                                     body_text_clean  \\\n",
              "0  Go until jurong point crazy Available only in ...   \n",
              "1                            Ok lar Joking wif u oni   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3        U dun say so early hor U c already then say   \n",
              "4  Nah I dont think he goes to usf he lives aroun...   \n",
              "\n",
              "                                 body_text_tokenized  \n",
              "0  [Go, until, jurong, point, crazy, Available, o...  \n",
              "1                     [Ok, lar, Joking, wif, u, oni]  \n",
              "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
              "3  [U, dun, say, so, early, hor, U, c, already, t...  \n",
              "4  [Nah, I, dont, think, he, goes, to, usf, he, l...  "
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "#function to apply tokenization\n",
        "def tokenize(text):\n",
        "    tokens = re.split(\"\\W+\", text)# W+ means all capital, small alphabets and integers 0-9\n",
        "    return tokens\n",
        "\n",
        "df[\"body_text_tokenized\"] = df[\"body_text_clean\"].apply(lambda x: tokenize(x))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH0wqqTF1MD1"
      },
      "outputs": [],
      "source": [
        "#!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFYIKBzp2R3V"
      },
      "source": [
        "Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSs1FF5l1MMJ",
        "outputId": "003046db-90af-4e38-964b-512299829ecc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\kldat\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "C-34yGp91MVE",
        "outputId": "693d4ded-b61d-4676-b4d0-d6b53fd5bdcd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nonstop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
              "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
              "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
              "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Type  \\\n",
              "0  Go until jurong point, crazy.. Available only ...   ham   \n",
              "1                      Ok lar... Joking wif u oni...   ham   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam   \n",
              "3  U dun say so early hor... U c already then say...   ham   \n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham   \n",
              "\n",
              "                                     body_text_clean  \\\n",
              "0  Go until jurong point crazy Available only in ...   \n",
              "1                            Ok lar Joking wif u oni   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3        U dun say so early hor U c already then say   \n",
              "4  Nah I dont think he goes to usf he lives aroun...   \n",
              "\n",
              "                                 body_text_tokenized  \\\n",
              "0  [Go, until, jurong, point, crazy, Available, o...   \n",
              "1                     [Ok, lar, Joking, wif, u, oni]   \n",
              "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
              "3  [U, dun, say, so, early, hor, U, c, already, t...   \n",
              "4  [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
              "\n",
              "                                   body_text_nonstop  \n",
              "0  [Go, jurong, point, crazy, Available, bugis, n...  \n",
              "1                     [Ok, lar, Joking, wif, u, oni]  \n",
              "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
              "3      [U, dun, say, early, hor, U, c, already, say]  \n",
              "4  [Nah, I, dont, think, goes, usf, lives, around...  "
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "def remove_stopwords(token):\n",
        "    text = [word for word in token if word not in stopwords]# to remove all stopwords\n",
        "    return text\n",
        "\n",
        "df[\"body_text_nonstop\"] = df[\"body_text_tokenized\"].apply(lambda x: remove_stopwords(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_q2w89i2Xjy"
      },
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "cGPbqBvv0_bU",
        "outputId": "ea8723a9-7b4c-4312-f1e8-863e132a5612"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nonstop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
              "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
              "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
              "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
              "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
              "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
              "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
              "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Type  \\\n",
              "0  Go until jurong point, crazy.. Available only ...   ham   \n",
              "1                      Ok lar... Joking wif u oni...   ham   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam   \n",
              "3  U dun say so early hor... U c already then say...   ham   \n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham   \n",
              "\n",
              "                                     body_text_clean  \\\n",
              "0  Go until jurong point crazy Available only in ...   \n",
              "1                            Ok lar Joking wif u oni   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3        U dun say so early hor U c already then say   \n",
              "4  Nah I dont think he goes to usf he lives aroun...   \n",
              "\n",
              "                                 body_text_tokenized  \\\n",
              "0  [Go, until, jurong, point, crazy, Available, o...   \n",
              "1                     [Ok, lar, Joking, wif, u, oni]   \n",
              "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
              "3  [U, dun, say, so, early, hor, U, c, already, t...   \n",
              "4  [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
              "\n",
              "                                   body_text_nonstop  \\\n",
              "0  [Go, jurong, point, crazy, Available, bugis, n...   \n",
              "1                     [Ok, lar, Joking, wif, u, oni]   \n",
              "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
              "3      [U, dun, say, early, hor, U, c, already, say]   \n",
              "4  [Nah, I, dont, think, goes, usf, lives, around...   \n",
              "\n",
              "                                   body_text_stemmed  \n",
              "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
              "1                       [ok, lar, joke, wif, u, oni]  \n",
              "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
              "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
              "4  [nah, i, dont, think, goe, usf, live, around, ...  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def stemming(t_text):\n",
        "    text = [ps.stem(word) for word in t_text]\n",
        "    return text\n",
        "\n",
        "df[\"body_text_stemmed\"] = df[\"body_text_nonstop\"].apply(lambda x: stemming(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6UNf6_82dbE"
      },
      "source": [
        "Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kWu9T8Q0_ZI",
        "outputId": "5e4983dc-8baa-4599-e456-7524b2a9bc2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\kldat\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY5mzvU8lkXy",
        "outputId": "199a0043-f65f-443d-d60f-d453e96d81dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\kldat\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rU2B4xo10_Wn",
        "outputId": "1cb926dd-96e7-440e-d583-2609e15a3e05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Type</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nonstop</th>\n",
              "      <th>body_text_stemmed</th>\n",
              "      <th>body_text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point crazy Available only in ...</td>\n",
              "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
              "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
              "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
              "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
              "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
              "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
              "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor U c already then say</td>\n",
              "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
              "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
              "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
              "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
              "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
              "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
              "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Type  \\\n",
              "0  Go until jurong point, crazy.. Available only ...   ham   \n",
              "1                      Ok lar... Joking wif u oni...   ham   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam   \n",
              "3  U dun say so early hor... U c already then say...   ham   \n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham   \n",
              "\n",
              "                                     body_text_clean  \\\n",
              "0  Go until jurong point crazy Available only in ...   \n",
              "1                            Ok lar Joking wif u oni   \n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3        U dun say so early hor U c already then say   \n",
              "4  Nah I dont think he goes to usf he lives aroun...   \n",
              "\n",
              "                                 body_text_tokenized  \\\n",
              "0  [Go, until, jurong, point, crazy, Available, o...   \n",
              "1                     [Ok, lar, Joking, wif, u, oni]   \n",
              "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
              "3  [U, dun, say, so, early, hor, U, c, already, t...   \n",
              "4  [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
              "\n",
              "                                   body_text_nonstop  \\\n",
              "0  [Go, jurong, point, crazy, Available, bugis, n...   \n",
              "1                     [Ok, lar, Joking, wif, u, oni]   \n",
              "2  [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
              "3      [U, dun, say, early, hor, U, c, already, say]   \n",
              "4  [Nah, I, dont, think, goes, usf, lives, around...   \n",
              "\n",
              "                                   body_text_stemmed  \\\n",
              "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
              "1                       [ok, lar, joke, wif, u, oni]   \n",
              "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
              "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
              "4  [nah, i, dont, think, goe, usf, live, around, ...   \n",
              "\n",
              "                                body_text_lemmatized  \n",
              "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
              "1                       [ok, lar, joke, wif, u, oni]  \n",
              "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
              "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
              "4  [nah, i, dont, think, goe, usf, live, around, ...  "
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatizer(t_text):\n",
        "    text = [wn.lemmatize(word) for word in t_text]\n",
        "    return text\n",
        "\n",
        "df[\"body_text_lemmatized\"] = df[\"body_text_stemmed\"].apply(lambda x: lemmatizer(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz-CTOAO0_Ur"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"pre_processed_data.csv\", sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQDVj_Bb0_QI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "data = pd.read_csv(\"pre_processed_data.csv\", sep=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfjTJ6i93A4Z"
      },
      "source": [
        "Apply Count Vectorizer\n",
        "\n",
        "1. Convert the text into lower case\n",
        "2. Remove punctuations\n",
        "3. Split the text into tokens\n",
        "4. Remove all stop words\n",
        "5. Stems each word in the text using the porter stemmer algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To1nqEew3Ba_"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSjbXij93La1"
      },
      "source": [
        "1. We are using Count vectorizer to transform the text data into a matrix of token counts.\n",
        "2. The function, get_feature_names_out method return the list of feature names(tokens) in the order they appear in the matrix. These feature names represent the vocabolary of the CountVectorizer model from the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2bZ1azx3LFI"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(analyzer=clean_text)\n",
        "x_count = count.fit_transform(data[\"Tweet\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DPrn6mjWIYL",
        "outputId": "726d11d9-d0a1-452b-ca6d-464996dc82b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<20469x37328 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 174781 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDgeRbur3CFy"
      },
      "outputs": [],
      "source": [
        "x_count_df = pd.DataFrame(x_count.toarray(), columns=count.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt_UAZtNCdCF",
        "outputId": "5b3c45b5-7f3a-417a-8b26-7dc4beeb25a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16375,)\n",
            "(4094,)\n",
            "(16375,)\n",
            "(4094,)\n"
          ]
        }
      ],
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "X = data.body_text_clean\n",
        "y = data.Type\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vn-WohbaDcuj",
        "outputId": "f4c646d8-7160-46cb-a309-8c027f37d0af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# instantiate the vectorizer\n",
        "vect = CountVectorizer()\n",
        "vect.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbuEDJzcCc-5",
        "outputId": "5208701f-b303-470a-e022-a9cf54f73506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<16375x36684 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 192966 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# learn training data vocabulary, then use it to create a document-term matrix\n",
        "X_train_dtm = vect.transform(X_train)\n",
        "\n",
        "# equivalently: combine fit and transform into a single step\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "\n",
        "# examine the document-term matrix\n",
        "X_train_dtm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT9jKX4v3CBI",
        "outputId": "8df43ac6-d3e3-4291-a2c8-5f38f62e47d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4094x36684 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 41214 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "X_test_dtm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEe6rmbWEE39",
        "outputId": "55e44530-c60f-4b77-81e5-2ab932ebcc76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<16375x36684 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 192966 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidf_transformer.fit(X_train_dtm)\n",
        "tfidf_transformer.transform(X_train_dtm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4RYF8xZ8Q4F"
      },
      "source": [
        "Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTkdk2BT3B_N",
        "outputId": "58c604a5-ce91-41ad-831e-03bfef749520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naives Theorem Accuracy: 0.82266731802638\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_test_dtm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Multinomial Naives Theorem Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYNpTFUA3B9U",
        "outputId": "ef720bbd-c1ed-4b51-eef4-b5219294a210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.8041035661944309\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_test_dtm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('SVM Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LspBxrY3B7S",
        "outputId": "fb6df6f3-63e9-4d52-e55e-92c7022407bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Accuracy: 0.7484123106985833\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_test_dtm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Gradient Boosting Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGEw60nj3B5l",
        "outputId": "a02a333a-cc89-4571-ddc0-211eb4680feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8243771372740596\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_test_dtm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Logistic Regression Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htrb9jG33B3k",
        "outputId": "f515aa77-383e-4ce6-8e8e-bd30af6d2c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Accuracy: 0.7725940400586224\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_test_dtm)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Decision Tree Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLkeElVfE_8p"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q9uHSS30_Mu",
        "outputId": "f2b5b7af-1ef9-4fc4-8586-cb171713a915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naives Theorem Accuracy: 0.9229312977099237\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_train_dtm)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print('Multinomial Naives Theorem Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPX_Vmz60_Kb",
        "outputId": "df978672-2891-49e4-fd89-0ee0f490a590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.9483969465648855\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_train_dtm)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print('SVM Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl5H4Sa_FjAX",
        "outputId": "87e82661-56ed-45c1-decf-2707759fa273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Accuracy: 0.7660458015267175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_train_dtm)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print('Gradient Boosting Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApiHfsrqFoL6",
        "outputId": "e91f2384-1f69-4e02-afc4-52c91e4d0c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.9865648854961832\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_train_dtm)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print('Logistic Regression Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1UDKVYVFtIK",
        "outputId": "af51e6d3-618e-4430-d7bd-bb2374a4d6a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Accuracy: 0.9999389312977099\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_train_dtm)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print('Decision Tree Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i0Dp5jBlkYK",
        "outputId": "8c3ae159-8980-449f-cd20-4f09b047cafb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<StringArray>\n",
              "[                                                                                                                                                                    '_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\\n@SaiPrav26957591\\nÂ·\\n5m\"KARMA\" is Boomerang  \\n\\nCSGay fans crying is my source of happiness.  Their tears work as glucose for my body, their screams bring peace to my ears. \\n\\nBest Scenery of this IPL \\n\\n#CSKvsRR',\n",
              "                                                                                                                                                                                                                                                                        'Rozana Spokesman\\n@RozanaSpokesman\\nÂ·\\n6m#IPL2023: #RajasthanRoyals beat #ChennaiSuperKings by 3 runs \\n\\n#CSKvsRR #RRvsCSK #IPLT20',\n",
              "                                                                                                          \"Broadcast Media\\n@vijendra_deepa\\nÂ·\\n6mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n\\n#SoppanaSundariFrom14April \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n @proyuvraaj\",\n",
              "                                                                                                                                                                                                                                                                                                   'Venky_K\\n@VenkyK_Offic\\nÂ·\\n6mBeautiful Video.. Dad Little Princess \\n\\n #SandeepSharma #CSKvsRR #MSDhoni',\n",
              "                                                                                                                        \"Albin Prince\\n@prinz_albin\\nÂ·\\n7mMy Man \\n@msdhoni\\n is playing with pain for us \\n\\nThe Man The Myth The Legend \\n\\nI'll be with him, always a #Thala fan\\n\\n#ThalaDhoni  #MSDhoniğ“ƒµ #CSKvsRR #ChennaiSuperKingsvsRajasthanRoyals #ChennaiSuperKings #CSK #GOAT #CSKvsRCB #SK21 #SK\",\n",
              "                                                                                                                                                                                                                                                        'Arman Malik\\n@Armanmalik9582\\nÂ·\\n8mMost Wins vs CSK at Chepauk\\n\\n5 - MI\\n2 - RR*\\n2 - DC\\n2 - KKR\\n2 - PBKS\\n2 - DEC\\n1 - PWI\\n1 - RCB\\n\\n#CSKvsRR',\n",
              "                                                                                                                                                                                                                                           'Monu Bhagwat\\n@imonubhagwat\\nÂ·\\n9mMahendra singh dhoni will always be the best finisher ever..\\n2.2 Cr viewvership ...mahi craze#CSKvsRR #RRvsCSK #MSDhoniğ“ƒµ #MSD',\n",
              "                                                                                                                                                                                 \"HT Sports\\n@HTSportsNews\\nÂ·\\n18mR Ashwin reacted to the umpires changing the ball for dew on their own. He also revealed that as a bowling team RR didn't ask for the ball to be changed\\n\\n#IPL #IPL2023 #CSKvsRR #CSKvRR\",\n",
              "                                                                                                                                                            'Kanak News\\n@kanak_news\\nÂ·\\n18mà¬¨à¬¿à¬²à¬¾à¬®à¬°à­‡ à¬¥à¬¿à¬²à­‡ à¬…à¬¨à¬¸à­‹à¬²à­à¬¡ à¥¤ à¬¬à¬¦à¬³ à¬–à­‡à¬³à¬¾à¬³à­€ à¬­à¬¾à¬¬à­‡ à¬¸à¬¾à¬®à¬¿à¬² à¬¹à­‡à¬²à­‡, à¬®à¬¾à¬¹à¬¿à¬™à­à¬•à­ à¬®à¬¾à¬¤à­ à¬¦à­‡à¬‡ à¬°à¬¾à¬œà¬¸à­à¬¥à¬¾à¬¨à¬•à­ à¬¬à¬¿à¬œà­Ÿ à¬­à­‡à¬Ÿà¬¿ à¬¦à­‡à¬²à­‡ à¥¤ #KanakNews \\n@IPL\\n  #Cricket #CSKvsRR \\nhttps://kanaknews.com/sandeep-sharma-wins-heart-after-rajasthans-win/â€¦',\n",
              "                                                                                                                                                                                                                                                                                                                          'Jashpal Machhar\\n@jashpal_machhar\\nÂ·\\n18mMahendra Singh dhoni\\n#MSDhoniğ“ƒµ #CSKvsRR',\n",
              "                                                                                         'FilmyDude\\n@ItsFilmyDude\\nÂ·\\n18mhttps://filmydude.com/bhediya2-a-new-horror-comedy-film/â€¦\\n#Bhediya2 : A New Horror-Comedy Film\\n\\n#VarunDhawan is back...  The release date of Stree 2 and Bhediya 2 has been announced in 2025.  Congratulations India #Bhediya2 #VarunDhawan #Stree2 #TejRan #CSKvsRR #wtcfinal',\n",
              "                                                                                                                                                                                                                                                                                          \"Crickaith\\n@Crickaith\\nÂ·\\n19m#MSDhoni got emotional after seeing his first love's look-alike in #CSKvsRR #IPL2023\",\n",
              "                                                                                                                                                  'Mooha Swartz\\n@CyberAnonymous\\nÂ·\\n19mtimesofindia: RT \\n@toisports\\n: How vintage Dhoni rolled back the clock, but Rajasthan Royals still managed to beat CSK\\n\\nSTORY IN IMAGES: https://bit.ly/3GAIgGM\\n\\n#MSDhoni #CSKvsRR #IPL2023 #ChennaiSuperKings',\n",
              "                                                                                          \"Kollywood Scope - Tamil Cinema\\n@KollywoodScope\\nÂ·\\n20mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n\\n#SoppanaSundariFrom14April \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n @proyuvraaj\",\n",
              "                                                                                                                                                                                                                                                                           'Wisden India\\n@WisdenIndia\\nÂ·\\n27m41-year-old MS Dhoni is still going strong in IPL \\n\\n#MSDhoni #CSK #CSKvsRR #IPL2023 #Cricket',\n",
              "                                                       'Cricreads\\n@cricreads\\nÂ·\\n28mâ€˜I can hit it for a sixâ€¦â€™: Dhoni reveals incidents from Sandeepâ€™s last over https://cricreads.com/i-can-hit-it-for-a-six-dhoni-reveals-incidents-from-sandeeps-last-over/â€¦ via \\n@Cricreads\\n#MSDhoni #RaviShastri #SandeepSharma #ChennaiSuperKings #RajasthanRoyals #WhistlePodu #HallaBol #TATAIPL #CSKvsRR #RRvsCSK',\n",
              "                                                                                    \"Srivathsan\\n@ImSrivathsanS\\nÂ·\\n28m#RCB would have lost yesterday's match !! Any RCB bowler would have given away that last ball 6 !! RCB needs to dismantle their team and start from beginning. First get rid of the  management which thinks Harshal Patel can be our death bowler at Chinnaswamy !! #CSKvRR #CSKvsRR\",\n",
              "                                                                                    'LALIT PAWAR\\n@LALITPA66496881\\nÂ·\\n29mDream transforms into thoughts, thoughts results into action ///////\\n#SaturdayVibes  #AlluArjunğ“ƒµ #ShehnaazGill #Pushpa2TheRule #YaliCapkini #YemiCregx #weareoneEXO #AgustD #Pushpa2 #Pushpa #SUGA #Nil #ProudOfYouDidi #KolkataMetro #DeepikaPadukone #Bhediya2 #Stree2 #CSKvsRR',\n",
              "                                                                                                                                                                                                                                                  'Thanthi TV\\n@ThanthiTV\\nÂ·\\n30m\"à®¤à¯‹à®©à®¿à®•à¯à®•à¯ à®•à®¾à®¯à®®à¯.. à®®à¯à®•à¯à®•à®¿à®¯ à®µà¯€à®°à®°à¯ 3 à®®à¯‡à®Ÿà¯à®šà¯ à®†à®Ÿ à®®à®¾à®Ÿà¯à®Ÿà®¾à®°à¯\" - CSK à®°à®šà®¿à®•à®°à¯à®•à®³à¯à®•à¯à®•à¯ à®…à®¤à®¿à®°à¯à®šà¯à®šà®¿ à®¤à®•à®µà®²à¯\\n\\n#csk #ipl2023 #magala #cskvsrr',\n",
              "                                                                                                                                                                                                                                                                                                     'Yaar Paatha Vela Da Ithu\\n@YPVDI_Page\\nÂ·\\n30m after the Yesterday match  #CSKvsRR\\n\\n#CSKians #Paltans',\n",
              "                                                                                                                            \"INSubcontinent News\\n@INPrimeMinister\\nÂ·\\n31mB'luru man objects to dogs pooping in front of house, murdered - Follow/RT/Fav - : #NatureLovers : #INTERNATIONALJATDAY : #JallianwalaBaghMassacre : #CSKvsRR : Nature Campaign : : : #GodMorningThursday : sab gazab by badshah :\",\n",
              "                                                                                                                                                                                                             'Jaya Plus\\n@jayapluschannel\\nÂ·\\n31mà®šà¯†à®©à¯à®©à¯ˆ à®šà¯‡à®ªà¯à®ªà®¾à®•à¯à®•à®®à¯ à®®à¯ˆà®¤à®¾à®©à®¤à¯à®¤à®¿à®²à¯ CSK - RR à®ªà¯‹à®Ÿà¯à®Ÿà®¿à®¯à¯ˆ à®¨à¯‡à®°à®¿à®²à¯ à®•à®£à¯à®Ÿà¯à®•à®³à®¿à®¤à¯à®¤ à®¨à®Ÿà®¿à®•à¯ˆ à®ªà®¿à®¨à¯à®¤à¯à®®à®¾à®¤à®µà®¿!\\n@thebindumadhavi\\n #Chepaukstadium #CSKvsRR #Bindumadhavi #JayaPlus',\n",
              "                                                                             'Sports Tak\\n@sports_tak\\nÂ·\\n38mCSK vs RR: à¤§à¥‹à¤¨à¥€ à¤•à¥‡ à¤—à¤¢à¤¼ à¤®à¥‡à¤‚ à¤¹à¤²à¥à¤²à¤¾ à¤¬à¥‹à¤², 15 à¤¸à¤¾à¤² à¤¬à¤¾à¤¦ à¤šà¥‡à¤¨à¥à¤¨à¤ˆ à¤®à¥‡à¤‚ à¤œà¥€à¤¤à¤¾ à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨, à¤šà¥‡à¤ªà¥‰à¤• à¤•à¥‡ à¤¯à¥‡ à¤†à¤‚à¤•à¤¡à¤¼à¥‡ à¤¹à¥ˆà¤°à¤¾à¤¨ à¤•à¤°à¤¨à¥‡ à¤µà¤¾à¤²à¥‡\\n@IPL\\n @ChennaiIPL\\n#IPL2023 #CSKvsRR\\nhttps://hindi.thesportstak.com/cricket-news/csk-vs-rr-ipl-2023-records-ms-dhoni-chennai-super-kings-record-rajasthan-royals-sanju-samsonâ€¦',\n",
              "                                                                                                                                                                                                                                                                 'Sportskeeda\\n@Sportskeeda\\nÂ·\\n38mRajasthan Royals have now won the most games against CSK since 2020 \\n\\n#CricketTwitter #IPL2023 #cskvsrr',\n",
              "                                                                                                                   \"Filmywood\\n@Filmy_Wood\\nÂ·\\n39mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n\\n#SoppanaSundariFrom14April \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n @proyuvraaj\",\n",
              "                                                                                                              'Fantasy11\\n@Dream11Guruji\\nÂ·\\n40mWon Huge Last Night in #CskvsRR .\\nGreat Match...Happy to See Msd with Great Knock ...If you Also Want to br Part Of My Winnings....You can join Us on telegram:-https://t.me/+Rn_P7MDmY2IAVslwâ€¦\\nOr Whatsapp us on 9122906061 \\n#csk #RR #GTvsPBKS #dream11',\n",
              "                                                                                                                                                                                                                                                                         \"Zee News\\n@ZeeNews\\nÂ·\\n40m'à¤®à¥ˆà¤‚ à¤¹à¥ˆà¤°à¤¾à¤¨ à¤¹à¥‚à¤‚', à¤…à¤¶à¥à¤µà¤¿à¤¨ à¤¨à¥‡ à¤…à¤‚à¤ªà¤¾à¤¯à¤° à¤ªà¤° à¤²à¤—à¤¾à¤ à¤¯à¥‡ à¤—à¤‚à¤­à¥€à¤° à¤†à¤°à¥‹à¤ª; IPL à¤®à¥‡à¤‚ à¤ªà¥ˆà¤¦à¤¾ à¤¹à¥à¤† à¤¨à¤¯à¤¾ à¤µà¤¿à¤µà¤¾à¤¦\\n\\n#IPL2023 #CSKvsRR\",\n",
              "                                                                                           \"Pratyush Garg\\n@GargPratyush27\\nÂ·\\n40mA record 2.3 Crore accounts on Jio Cinema were watching the last over of yesterday's match when Mentor Singh Dhoni was at the crease. In the current Indian list of players, only he could have managed this level of viewership. Thala for a reason.\\n\\n#CSKvsRR #IPL2023\",\n",
              "                                                                                                                                                                                                                                  'The CRITIQUE\\n@PrinceAvmk1\\nÂ·\\n41mMy tweet before match , As expected pure talent show  #SanjuSamson Captaincy #MSDhoniğ“ƒµ Falt shots  #CSKvsRR Masssss Entertaining Match ',\n",
              "                         \"Hamsini Entertainment\\n@Hamsinient\\nÂ·\\n51mOur #SoppanaSundari team  promoted the film at the #CSKvsRR match at Chepauk last night..\\n\\nDon't miss this laugh riot in theaters.. Bookings Open now  https://in.bookmyshow.com/chennai/movies/soppana-sundari/ET00355707â€¦ \\n\\n#SoppanaSundariFrom14April \\n@aishu_dil\\n @SGCharles2\\n @LakshmiPriyaaC\\n @vivek4kr\\n @Mani_Rajeshh\\nâ€¦\",\n",
              "                                                                                                                                                                                                 'TamilaninCinema\\n@TamilaninCinema\\nÂ·\\n51mTeam #SoppanaSundari Promoted The Film At #CSKvsRR Match At Chepauk Last Night\\n\\n#SoppanaSundariFrom14April  ! \\n@aishu_dil\\n @Hamsinient\\n !  \\n@proyuvraaj\\n !',\n",
              "                                                                                                                                                                                                                    'amit bishnoi\\n@ImAmitBishnoi\\nÂ·\\n51m#MSDhoni Smashes 2 Sixes in Final Over but Sandeep Sharma did not allow MS Dhoni and Ravindra Jadeja to reach the target. #RajasthanRoyals #CSKvsRR',\n",
              " 'Sandesh\\n@sandeshnews\\nÂ·\\n51mCSK àª¸àª¾àª®à«‡àª¨à«€ àªœà«€àª¤ àª¬àª¾àª¦ àªªàª£ Sanju Samsonàª¨à«‡ àª«àªŸàª•àª¾àª°à«àª¯à«‹ àª¦àª‚àª¡, àª¤à«‹àª¡à«àª¯à«‹ ICCàª¨à«‹ àª† àª®àª¹àª¤à«àª¤à«àªµàª¨à«‹ àª¨àª¿àª¯àª®, àª«àª°à«€ àª†àªµà«àª‚ àª•àª°à«àª¯à«àª‚ àª¤à«‹ àª²àª¾àª—àª¶à«‡ àªªà«àª°àª¤àª¿àª¬àª‚àª§!\\n\\n#CSKvsRR #SanjuSamson #ICCCodeOFConduct  #ICCRules #SlowOverRate\\n\\nhttps://sandesh.com/sports/icc-fined-rajasthan-royals-captain-sanju-samson-rs-12-lakh-for-slow-over-rateâ€¦\\n\\nàªµàª§à« àª¸àª®àª¾àªšàª¾àª° àªµàª¾àª‚àªšàªµàª¾ àª¡àª¾àª‰àª¨àª²à«‹àª¡ àª•àª°à«‹ àª¸àª‚àª¦à«‡àª¶ àª¨à«àª¯à«‚àª àªàªª : https://sandesh.com/d',\n",
              "                                                                                                                                                                                                                                                               'ABP Ananda\\n@abpanandatv\\nÂ·\\n51mà¦°à¦¾à¦œà¦¸à§à¦¥à¦¾à¦¨ à¦®à§à¦¯à¦¾à¦šà§‡à¦° à¦ªà¦°à§‡à¦‡ à¦§à§‹à¦¨à¦¿à¦° à¦šà§‹à¦Ÿ à¦¨à¦¿à¦¯à¦¼à§‡ à¦®à§à¦–à§‡ à¦–à§‹à¦²à§‡à¦¨ à¦«à§à¦²à§‡à¦®à¦¿à¦‚\\n#IPL2023 #IPLT20 #MSDhoni #StephenFleming #CSKvsRR',\n",
              "                                                                                                                     'Crude & Nifty Daily View\\n@hemakaroonya1\\nÂ·\\n52m13/04 : \"Nifty\\'s Capital Protection Method \" \\n\\n ( catch 40 to 50 points ) \\n\\n 2ND CALL ; Nifty Sold at 17787\\n\\n  #Crude #WTI #Nifty #NiftyBank #niftyOptions #CrudeOil #crude #ThalapathyVijay #Yorker #MSDhoni #CSKvsRR #IPL2023',\n",
              "                                                                                                                                   \"Kolly Buzz\\n@KollyBuzz\\nÂ·\\n53mThe unit of Actress \\n@aishu_dil\\n's laugh riot #SoppanaSundari, promoted the film at the #CSKvsRR match at Chepauk last night. \\n@SGCharles2\\n @LakshmiPriyaaC\\n @Hamsinient\\n @HueboxStudios\\n @ahimsafilms\\n #SoppanaSundariFrom14April\",\n",
              "                                                                                                                                                                                                                                                          'Times Now Sports\\n@timesnowsports\\nÂ·\\n1h#MSDhoni #RavichandranAshwin #CSKvsRR\\n@msdhoni\\n almost pulled off yet another run-chase.\\n@ashwinravi99',\n",
              "                                                                                                                                                                                'Hindustan Times Marathi\\n@htmarathi\\nÂ·\\n1hCSK vs RR: à¤†à¤¯à¤ªà¥€à¤à¤² à¥¨à¥¦à¥¨à¥© à¤šà¥à¤¯à¤¾ à¥§à¥­à¤µà¥à¤¯à¤¾ à¤¸à¤¾à¤®à¤¨à¥à¤¯à¤¾à¤¤ à¤šà¥‡à¤¨à¥à¤¨à¤ˆ à¤¸à¥à¤ªà¤°à¤•à¤¿à¤‚à¤—à¥à¤œà¤šà¥à¤¯à¤¾ à¤¸à¤‚à¤˜à¤¾à¤²à¤¾ à¥© à¤§à¤¾à¤µà¤¾à¤‚à¤¨à¥€ à¤ªà¤°à¤¾à¤­à¤µ à¤¸à¥à¤µà¥€à¤•à¤¾à¤°à¤¾à¤µà¤¾ à¤²à¤¾à¤—à¤²à¤¾.\\n\\n#IPL #IPL2023 #CSKvsRR #ChennaiSuperKings #RajasthanRoyals #MSDhoni',\n",
              "                                                                          'Sumit Mukherjee\\n@Who_Sumit\\nÂ·\\n1hMost IPL matches as Captain for a Team\\n\\n200 - Dhoni for CSK\\n146 - Rohit for MI\\n140 - Kohli for RCB \\n108 - Gambhir for KKR\\n\\n#IPL2023 #CSKvsRR #CSKvRR #RRvsCSK #RRvCSK #MSDhoni #Yellove #RajasthanRoyals #PBKSvGT #SanjuSamson #JosButtler #SandeepSharma #GTvPBKS  #IndianPremierLeague',\n",
              "                                                                                                                                                                                                                                                                               'Akash Purohit\\n@earthtoakash\\nÂ·\\n1hà¤•à¤¾à¤² à¤°à¥‡ à¤®à¥ˆà¤š à¤®à¤¾à¤¯ RR à¤²à¤¾à¤‡à¤µ à¤°à¥€ à¤•à¥€ à¤à¤²à¤•à¤¿à¤¯à¤¾à¤à¥¤\\n#Royals #RR #CSKvsRR #à¤°à¤¾à¤œà¤¸à¥à¤¥à¤¾à¤¨à¥€\\n\\n:- \\n@JioCinema',\n",
              "                                                                                                                                                                                                                              'Ruchita Jain #savesoil\\n@Ruchitaamehtaa\\nÂ·\\n1hNamaskaram #MSDhoni #ChennaiSuperKings #CSKvsRR #ishafoundation #ishayoga #sadhguru #IshaFoundation #Sadhguru \\n@ishafoundation']\n",
              "Length: 41, dtype: string"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5zNPaqJlkYL"
      },
      "source": [
        "My_Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zunaR93RlkYL",
        "outputId": "320500ee-b256-4e2a-8d9a-0e131912327b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>Handle</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Text</th>\n",
              "      <th>Emojis</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢</td>\n",
              "      <td>@SaiPrav26957591</td>\n",
              "      <td>2023-04-13T07:51:05.000Z</td>\n",
              "      <td>_ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\n",
              "@SaiPrav26957591\n",
              "Â·\n",
              "5m\"KARMA\" is ...</td>\n",
              "      <td>ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rozana Spokesman</td>\n",
              "      <td>@RozanaSpokesman</td>\n",
              "      <td>2023-04-13T07:50:34.000Z</td>\n",
              "      <td>Rozana Spokesman\n",
              "@RozanaSpokesman\n",
              "Â·\n",
              "6m#IPL2023...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Broadcast Media</td>\n",
              "      <td>@vijendra_deepa</td>\n",
              "      <td>2023-04-13T07:50:11.000Z</td>\n",
              "      <td>Broadcast Media\n",
              "@vijendra_deepa\n",
              "Â·\n",
              "6mThe unit o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Venky_K</td>\n",
              "      <td>@VenkyK_Offic</td>\n",
              "      <td>2023-04-13T07:49:37.000Z</td>\n",
              "      <td>Venky_K\n",
              "@VenkyK_Offic\n",
              "Â·\n",
              "6mBeautiful Video.. Da...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albin Prince</td>\n",
              "      <td>@prinz_albin</td>\n",
              "      <td>2023-04-13T07:48:57.000Z</td>\n",
              "      <td>Albin Prince\n",
              "@prinz_albin\n",
              "Â·\n",
              "7mMy Man \n",
              "@msdhoni...</td>\n",
              "      <td>ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Arman Malik</td>\n",
              "      <td>@Armanmalik9582</td>\n",
              "      <td>2023-04-13T07:48:32.000Z</td>\n",
              "      <td>Arman Malik\n",
              "@Armanmalik9582\n",
              "Â·\n",
              "8mMost Wins vs C...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Monu Bhagwat</td>\n",
              "      <td>@imonubhagwat</td>\n",
              "      <td>2023-04-13T07:46:40.000Z</td>\n",
              "      <td>Monu Bhagwat\n",
              "@imonubhagwat\n",
              "Â·\n",
              "9mMahendra singh ...</td>\n",
              "      <td>ğŸ¤©</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HT Sports</td>\n",
              "      <td>@HTSportsNews</td>\n",
              "      <td>2023-04-13T07:39:02.000Z</td>\n",
              "      <td>HT Sports\n",
              "@HTSportsNews\n",
              "Â·\n",
              "18mR Ashwin reacted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Kanak News</td>\n",
              "      <td>@kanak_news</td>\n",
              "      <td>2023-04-13T07:38:23.000Z</td>\n",
              "      <td>Kanak News\n",
              "@kanak_news\n",
              "Â·\n",
              "18mà¬¨à¬¿à¬²à¬¾à¬®à¬°à­‡ à¬¥à¬¿à¬²à­‡ à¬…à¬¨à¬¸à­‹à¬²...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Jashpal Machhar</td>\n",
              "      <td>@jashpal_machhar</td>\n",
              "      <td>2023-04-13T07:38:10.000Z</td>\n",
              "      <td>Jashpal Machhar\n",
              "@jashpal_machhar\n",
              "Â·\n",
              "18mMahendra...</td>\n",
              "      <td>ğŸ”¥ ğŸ”¥</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>FilmyDude</td>\n",
              "      <td>@ItsFilmyDude</td>\n",
              "      <td>2023-04-13T07:38:07.000Z</td>\n",
              "      <td>FilmyDude\n",
              "@ItsFilmyDude\n",
              "Â·\n",
              "18mhttps://filmydude...</td>\n",
              "      <td>ğŸ“·</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Crickaith</td>\n",
              "      <td>@Crickaith</td>\n",
              "      <td>2023-04-13T07:37:37.000Z</td>\n",
              "      <td>Crickaith\n",
              "@Crickaith\n",
              "Â·\n",
              "19m#MSDhoni got emotion...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mooha Swartz</td>\n",
              "      <td>@CyberAnonymous</td>\n",
              "      <td>2023-04-13T07:37:21.000Z</td>\n",
              "      <td>Mooha Swartz\n",
              "@CyberAnonymous\n",
              "Â·\n",
              "19mtimesofindia...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Kollywood Scope - Tamil Cinema</td>\n",
              "      <td>@KollywoodScope</td>\n",
              "      <td>2023-04-13T07:36:40.000Z</td>\n",
              "      <td>Kollywood Scope - Tamil Cinema\n",
              "@KollywoodScope...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Wisden India</td>\n",
              "      <td>@WisdenIndia</td>\n",
              "      <td>2023-04-13T07:30:00.000Z</td>\n",
              "      <td>Wisden India\n",
              "@WisdenIndia\n",
              "Â·\n",
              "27m41-year-old MS ...</td>\n",
              "      <td>ğŸ’ª</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Cricreads</td>\n",
              "      <td>@cricreads</td>\n",
              "      <td>2023-04-13T07:28:36.000Z</td>\n",
              "      <td>Cricreads\n",
              "@cricreads\n",
              "Â·\n",
              "28mâ€˜I can hit it for a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Srivathsan</td>\n",
              "      <td>@ImSrivathsanS</td>\n",
              "      <td>2023-04-13T07:28:36.000Z</td>\n",
              "      <td>Srivathsan\n",
              "@ImSrivathsanS\n",
              "Â·\n",
              "28m#RCB would have...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LALIT PAWAR</td>\n",
              "      <td>@LALITPA66496881</td>\n",
              "      <td>2023-04-13T07:27:57.000Z</td>\n",
              "      <td>LALIT PAWAR\n",
              "@LALITPA66496881\n",
              "Â·\n",
              "29mDream transf...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Thanthi TV</td>\n",
              "      <td>@ThanthiTV</td>\n",
              "      <td>2023-04-13T07:27:04.000Z</td>\n",
              "      <td>Thanthi TV\n",
              "@ThanthiTV\n",
              "Â·\n",
              "30m\"à®¤à¯‹à®©à®¿à®•à¯à®•à¯ à®•à®¾à®¯à®®à¯.. à®®...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Yaar Paatha Vela Da Ithu</td>\n",
              "      <td>@YPVDI_Page</td>\n",
              "      <td>2023-04-13T07:26:53.000Z</td>\n",
              "      <td>Yaar Paatha Vela Da Ithu\n",
              "@YPVDI_Page\n",
              "Â·\n",
              "30m aft...</td>\n",
              "      <td>ğŸ˜‚ ğŸ¤£ ğŸ¤ª</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>INSubcontinent News</td>\n",
              "      <td>@INPrimeMinister</td>\n",
              "      <td>2023-04-13T07:26:04.000Z</td>\n",
              "      <td>INSubcontinent News\n",
              "@INPrimeMinister\n",
              "Â·\n",
              "31mB'lu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Jaya Plus</td>\n",
              "      <td>@jayapluschannel</td>\n",
              "      <td>2023-04-13T07:25:33.000Z</td>\n",
              "      <td>Jaya Plus\n",
              "@jayapluschannel\n",
              "Â·\n",
              "31mà®šà¯†à®©à¯à®©à¯ˆ à®šà¯‡à®ªà¯à®ªà®¾à®•...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Sports Tak</td>\n",
              "      <td>@sports_tak</td>\n",
              "      <td>2023-04-13T07:18:24.000Z</td>\n",
              "      <td>Sports Tak\n",
              "@sports_tak\n",
              "Â·\n",
              "38mCSK vs RR: à¤§à¥‹à¤¨à¥€ à¤•à¥‡...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Sportskeeda</td>\n",
              "      <td>@Sportskeeda</td>\n",
              "      <td>2023-04-13T07:18:22.000Z</td>\n",
              "      <td>Sportskeeda\n",
              "@Sportskeeda\n",
              "Â·\n",
              "38mRajasthan Royals...</td>\n",
              "      <td>ğŸ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Filmywood</td>\n",
              "      <td>@Filmy_Wood</td>\n",
              "      <td>2023-04-13T07:18:05.000Z</td>\n",
              "      <td>Filmywood\n",
              "@Filmy_Wood\n",
              "Â·\n",
              "39mThe unit of Actress...</td>\n",
              "      <td>ğŸ¬ ğŸ ğŸ¿ ğŸ“½</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Fantasy11</td>\n",
              "      <td>@Dream11Guruji</td>\n",
              "      <td>2023-04-13T07:17:08.000Z</td>\n",
              "      <td>Fantasy11\n",
              "@Dream11Guruji\n",
              "Â·\n",
              "40mWon Huge Last Ni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Zee News</td>\n",
              "      <td>@ZeeNews</td>\n",
              "      <td>2023-04-13T07:16:54.000Z</td>\n",
              "      <td>Zee News\n",
              "@ZeeNews\n",
              "Â·\n",
              "40m'à¤®à¥ˆà¤‚ à¤¹à¥ˆà¤°à¤¾à¤¨ à¤¹à¥‚à¤‚', à¤…à¤¶à¥à¤µà¤¿à¤¨...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Pratyush Garg</td>\n",
              "      <td>@GargPratyush27</td>\n",
              "      <td>2023-04-13T07:16:27.000Z</td>\n",
              "      <td>Pratyush Garg\n",
              "@GargPratyush27\n",
              "Â·\n",
              "40mA record 2....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>The CRITIQUE</td>\n",
              "      <td>@PrinceAvmk1</td>\n",
              "      <td>2023-04-13T07:15:59.000Z</td>\n",
              "      <td>The CRITIQUE\n",
              "@PrinceAvmk1\n",
              "Â·\n",
              "41mMy tweet before...</td>\n",
              "      <td>ğŸ‘‡ ğŸ‘‡ ğŸ«¡ ğŸ«¡ ğŸ«¡ ğŸ”¥ ğŸ˜‚ ğŸ”¥ ğŸ¤© ğŸ«£</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Hamsini Entertainment</td>\n",
              "      <td>@Hamsinient</td>\n",
              "      <td>2023-04-13T07:06:06.000Z</td>\n",
              "      <td>Hamsini Entertainment\n",
              "@Hamsinient\n",
              "Â·\n",
              "51mOur #So...</td>\n",
              "      <td>ğŸŸ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>TamilaninCinema</td>\n",
              "      <td>@TamilaninCinema</td>\n",
              "      <td>2023-04-13T07:05:51.000Z</td>\n",
              "      <td>TamilaninCinema\n",
              "@TamilaninCinema\n",
              "Â·\n",
              "51mTeam #So...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>amit bishnoi</td>\n",
              "      <td>@ImAmitBishnoi</td>\n",
              "      <td>2023-04-13T07:05:42.000Z</td>\n",
              "      <td>amit bishnoi\n",
              "@ImAmitBishnoi\n",
              "Â·\n",
              "51m#MSDhoni Smas...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Sandesh</td>\n",
              "      <td>@sandeshnews</td>\n",
              "      <td>2023-04-13T07:05:39.000Z</td>\n",
              "      <td>Sandesh\n",
              "@sandeshnews\n",
              "Â·\n",
              "51mCSK àª¸àª¾àª®à«‡àª¨à«€ àªœà«€àª¤ àª¬àª¾àª¦ àªª...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>ABP Ananda</td>\n",
              "      <td>@abpanandatv</td>\n",
              "      <td>2023-04-13T07:05:29.000Z</td>\n",
              "      <td>ABP Ananda\n",
              "@abpanandatv\n",
              "Â·\n",
              "51mà¦°à¦¾à¦œà¦¸à§à¦¥à¦¾à¦¨ à¦®à§à¦¯à¦¾à¦šà§‡à¦° ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Crude &amp; Nifty Daily View</td>\n",
              "      <td>@hemakaroonya1</td>\n",
              "      <td>2023-04-13T07:04:41.000Z</td>\n",
              "      <td>Crude &amp; Nifty Daily View\n",
              "@hemakaroonya1\n",
              "Â·\n",
              "52m1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Kolly Buzz</td>\n",
              "      <td>@KollyBuzz</td>\n",
              "      <td>2023-04-13T07:04:06.000Z</td>\n",
              "      <td>Kolly Buzz\n",
              "@KollyBuzz\n",
              "Â·\n",
              "53mThe unit of Actress...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Times Now Sports</td>\n",
              "      <td>@timesnowsports</td>\n",
              "      <td>2023-04-13T06:55:57.000Z</td>\n",
              "      <td>Times Now Sports\n",
              "@timesnowsports\n",
              "Â·\n",
              "1h#MSDhoni ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Hindustan Times Marathi</td>\n",
              "      <td>@htmarathi</td>\n",
              "      <td>2023-04-13T06:55:25.000Z</td>\n",
              "      <td>Hindustan Times Marathi\n",
              "@htmarathi\n",
              "Â·\n",
              "1hCSK vs ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Sumit Mukherjee</td>\n",
              "      <td>@Who_Sumit</td>\n",
              "      <td>2023-04-13T06:55:08.000Z</td>\n",
              "      <td>Sumit Mukherjee\n",
              "@Who_Sumit\n",
              "Â·\n",
              "1hMost IPL matche...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Akash Purohit</td>\n",
              "      <td>@earthtoakash</td>\n",
              "      <td>2023-04-13T06:54:32.000Z</td>\n",
              "      <td>Akash Purohit\n",
              "@earthtoakash\n",
              "Â·\n",
              "1hà¤•à¤¾à¤² à¤°à¥‡ à¤®à¥ˆà¤š à¤®à¤¾à¤¯...</td>\n",
              "      <td>ğŸ“¸</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Ruchita Jain #savesoil</td>\n",
              "      <td>@Ruchitaamehtaa</td>\n",
              "      <td>2023-04-13T06:54:25.000Z</td>\n",
              "      <td>Ruchita Jain #savesoil\n",
              "@Ruchitaamehtaa\n",
              "Â·\n",
              "1hNam...</td>\n",
              "      <td>ğŸ™ ğŸŒ¸ ğŸ™Œ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          UserName            Handle  \\\n",
              "0                    _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢  @SaiPrav26957591   \n",
              "1                 Rozana Spokesman  @RozanaSpokesman   \n",
              "2                  Broadcast Media   @vijendra_deepa   \n",
              "3                          Venky_K     @VenkyK_Offic   \n",
              "4                     Albin Prince      @prinz_albin   \n",
              "5                      Arman Malik   @Armanmalik9582   \n",
              "6                     Monu Bhagwat     @imonubhagwat   \n",
              "7                        HT Sports     @HTSportsNews   \n",
              "8                       Kanak News       @kanak_news   \n",
              "9                  Jashpal Machhar  @jashpal_machhar   \n",
              "10                       FilmyDude     @ItsFilmyDude   \n",
              "11                       Crickaith        @Crickaith   \n",
              "12                    Mooha Swartz   @CyberAnonymous   \n",
              "13  Kollywood Scope - Tamil Cinema   @KollywoodScope   \n",
              "14                    Wisden India      @WisdenIndia   \n",
              "15                       Cricreads        @cricreads   \n",
              "16                      Srivathsan    @ImSrivathsanS   \n",
              "17                     LALIT PAWAR  @LALITPA66496881   \n",
              "18                      Thanthi TV        @ThanthiTV   \n",
              "19        Yaar Paatha Vela Da Ithu       @YPVDI_Page   \n",
              "20             INSubcontinent News  @INPrimeMinister   \n",
              "21                       Jaya Plus  @jayapluschannel   \n",
              "22                      Sports Tak       @sports_tak   \n",
              "23                     Sportskeeda      @Sportskeeda   \n",
              "24                       Filmywood       @Filmy_Wood   \n",
              "25                       Fantasy11    @Dream11Guruji   \n",
              "26                        Zee News          @ZeeNews   \n",
              "27                   Pratyush Garg   @GargPratyush27   \n",
              "28                    The CRITIQUE      @PrinceAvmk1   \n",
              "29           Hamsini Entertainment       @Hamsinient   \n",
              "30                 TamilaninCinema  @TamilaninCinema   \n",
              "31                    amit bishnoi    @ImAmitBishnoi   \n",
              "32                         Sandesh      @sandeshnews   \n",
              "33                      ABP Ananda      @abpanandatv   \n",
              "34        Crude & Nifty Daily View    @hemakaroonya1   \n",
              "35                      Kolly Buzz        @KollyBuzz   \n",
              "36                Times Now Sports   @timesnowsports   \n",
              "37         Hindustan Times Marathi        @htmarathi   \n",
              "38                 Sumit Mukherjee        @Who_Sumit   \n",
              "39                   Akash Purohit     @earthtoakash   \n",
              "40          Ruchita Jain #savesoil   @Ruchitaamehtaa   \n",
              "\n",
              "                   Timestamp  \\\n",
              "0   2023-04-13T07:51:05.000Z   \n",
              "1   2023-04-13T07:50:34.000Z   \n",
              "2   2023-04-13T07:50:11.000Z   \n",
              "3   2023-04-13T07:49:37.000Z   \n",
              "4   2023-04-13T07:48:57.000Z   \n",
              "5   2023-04-13T07:48:32.000Z   \n",
              "6   2023-04-13T07:46:40.000Z   \n",
              "7   2023-04-13T07:39:02.000Z   \n",
              "8   2023-04-13T07:38:23.000Z   \n",
              "9   2023-04-13T07:38:10.000Z   \n",
              "10  2023-04-13T07:38:07.000Z   \n",
              "11  2023-04-13T07:37:37.000Z   \n",
              "12  2023-04-13T07:37:21.000Z   \n",
              "13  2023-04-13T07:36:40.000Z   \n",
              "14  2023-04-13T07:30:00.000Z   \n",
              "15  2023-04-13T07:28:36.000Z   \n",
              "16  2023-04-13T07:28:36.000Z   \n",
              "17  2023-04-13T07:27:57.000Z   \n",
              "18  2023-04-13T07:27:04.000Z   \n",
              "19  2023-04-13T07:26:53.000Z   \n",
              "20  2023-04-13T07:26:04.000Z   \n",
              "21  2023-04-13T07:25:33.000Z   \n",
              "22  2023-04-13T07:18:24.000Z   \n",
              "23  2023-04-13T07:18:22.000Z   \n",
              "24  2023-04-13T07:18:05.000Z   \n",
              "25  2023-04-13T07:17:08.000Z   \n",
              "26  2023-04-13T07:16:54.000Z   \n",
              "27  2023-04-13T07:16:27.000Z   \n",
              "28  2023-04-13T07:15:59.000Z   \n",
              "29  2023-04-13T07:06:06.000Z   \n",
              "30  2023-04-13T07:05:51.000Z   \n",
              "31  2023-04-13T07:05:42.000Z   \n",
              "32  2023-04-13T07:05:39.000Z   \n",
              "33  2023-04-13T07:05:29.000Z   \n",
              "34  2023-04-13T07:04:41.000Z   \n",
              "35  2023-04-13T07:04:06.000Z   \n",
              "36  2023-04-13T06:55:57.000Z   \n",
              "37  2023-04-13T06:55:25.000Z   \n",
              "38  2023-04-13T06:55:08.000Z   \n",
              "39  2023-04-13T06:54:32.000Z   \n",
              "40  2023-04-13T06:54:25.000Z   \n",
              "\n",
              "                                                 Text               Emojis  \\\n",
              "0   _ğ—¡ğ—§ğ—¥ Ê³á¶œáµ‡á¶œáµ˜Ë¡áµ—Ë¢\n",
              "@SaiPrav26957591\n",
              "Â·\n",
              "5m\"KARMA\" is ...  ğŸ‡µ ğŸ‡· ğŸ‡¦ ğŸ‡» ğŸ‡ª ğŸ‡ª ğŸ‡³ ğŸ˜Š ğŸ˜Š ğŸ¤©   \n",
              "1   Rozana Spokesman\n",
              "@RozanaSpokesman\n",
              "Â·\n",
              "6m#IPL2023...                  NaN   \n",
              "2   Broadcast Media\n",
              "@vijendra_deepa\n",
              "Â·\n",
              "6mThe unit o...                  NaN   \n",
              "3   Venky_K\n",
              "@VenkyK_Offic\n",
              "Â·\n",
              "6mBeautiful Video.. Da...                  NaN   \n",
              "4   Albin Prince\n",
              "@prinz_albin\n",
              "Â·\n",
              "7mMy Man \n",
              "@msdhoni...    ğŸ˜­ ğŸ’› ğŸ¥¹ ğŸ› ğŸ”¥ ğŸ§ ğŸ’¥ â¤ ğŸ’¯   \n",
              "5   Arman Malik\n",
              "@Armanmalik9582\n",
              "Â·\n",
              "8mMost Wins vs C...                  NaN   \n",
              "6   Monu Bhagwat\n",
              "@imonubhagwat\n",
              "Â·\n",
              "9mMahendra singh ...                    ğŸ¤©   \n",
              "7   HT Sports\n",
              "@HTSportsNews\n",
              "Â·\n",
              "18mR Ashwin reacted ...                  NaN   \n",
              "8   Kanak News\n",
              "@kanak_news\n",
              "Â·\n",
              "18mà¬¨à¬¿à¬²à¬¾à¬®à¬°à­‡ à¬¥à¬¿à¬²à­‡ à¬…à¬¨à¬¸à­‹à¬²...                  NaN   \n",
              "9   Jashpal Machhar\n",
              "@jashpal_machhar\n",
              "Â·\n",
              "18mMahendra...                  ğŸ”¥ ğŸ”¥   \n",
              "10  FilmyDude\n",
              "@ItsFilmyDude\n",
              "Â·\n",
              "18mhttps://filmydude...                    ğŸ“·   \n",
              "11  Crickaith\n",
              "@Crickaith\n",
              "Â·\n",
              "19m#MSDhoni got emotion...                  NaN   \n",
              "12  Mooha Swartz\n",
              "@CyberAnonymous\n",
              "Â·\n",
              "19mtimesofindia...                  NaN   \n",
              "13  Kollywood Scope - Tamil Cinema\n",
              "@KollywoodScope...                  NaN   \n",
              "14  Wisden India\n",
              "@WisdenIndia\n",
              "Â·\n",
              "27m41-year-old MS ...                    ğŸ’ª   \n",
              "15  Cricreads\n",
              "@cricreads\n",
              "Â·\n",
              "28mâ€˜I can hit it for a ...                  NaN   \n",
              "16  Srivathsan\n",
              "@ImSrivathsanS\n",
              "Â·\n",
              "28m#RCB would have...                  NaN   \n",
              "17  LALIT PAWAR\n",
              "@LALITPA66496881\n",
              "Â·\n",
              "29mDream transf...                  NaN   \n",
              "18  Thanthi TV\n",
              "@ThanthiTV\n",
              "Â·\n",
              "30m\"à®¤à¯‹à®©à®¿à®•à¯à®•à¯ à®•à®¾à®¯à®®à¯.. à®®...                  NaN   \n",
              "19  Yaar Paatha Vela Da Ithu\n",
              "@YPVDI_Page\n",
              "Â·\n",
              "30m aft...                ğŸ˜‚ ğŸ¤£ ğŸ¤ª   \n",
              "20  INSubcontinent News\n",
              "@INPrimeMinister\n",
              "Â·\n",
              "31mB'lu...                  NaN   \n",
              "21  Jaya Plus\n",
              "@jayapluschannel\n",
              "Â·\n",
              "31mà®šà¯†à®©à¯à®©à¯ˆ à®šà¯‡à®ªà¯à®ªà®¾à®•...                  NaN   \n",
              "22  Sports Tak\n",
              "@sports_tak\n",
              "Â·\n",
              "38mCSK vs RR: à¤§à¥‹à¤¨à¥€ à¤•à¥‡...                  NaN   \n",
              "23  Sportskeeda\n",
              "@Sportskeeda\n",
              "Â·\n",
              "38mRajasthan Royals...                    ğŸ   \n",
              "24  Filmywood\n",
              "@Filmy_Wood\n",
              "Â·\n",
              "39mThe unit of Actress...              ğŸ¬ ğŸ ğŸ¿ ğŸ“½   \n",
              "25  Fantasy11\n",
              "@Dream11Guruji\n",
              "Â·\n",
              "40mWon Huge Last Ni...                  NaN   \n",
              "26  Zee News\n",
              "@ZeeNews\n",
              "Â·\n",
              "40m'à¤®à¥ˆà¤‚ à¤¹à¥ˆà¤°à¤¾à¤¨ à¤¹à¥‚à¤‚', à¤…à¤¶à¥à¤µà¤¿à¤¨...                  NaN   \n",
              "27  Pratyush Garg\n",
              "@GargPratyush27\n",
              "Â·\n",
              "40mA record 2....                  NaN   \n",
              "28  The CRITIQUE\n",
              "@PrinceAvmk1\n",
              "Â·\n",
              "41mMy tweet before...  ğŸ‘‡ ğŸ‘‡ ğŸ«¡ ğŸ«¡ ğŸ«¡ ğŸ”¥ ğŸ˜‚ ğŸ”¥ ğŸ¤© ğŸ«£   \n",
              "29  Hamsini Entertainment\n",
              "@Hamsinient\n",
              "Â·\n",
              "51mOur #So...                    ğŸŸ   \n",
              "30  TamilaninCinema\n",
              "@TamilaninCinema\n",
              "Â·\n",
              "51mTeam #So...                  NaN   \n",
              "31  amit bishnoi\n",
              "@ImAmitBishnoi\n",
              "Â·\n",
              "51m#MSDhoni Smas...                  NaN   \n",
              "32  Sandesh\n",
              "@sandeshnews\n",
              "Â·\n",
              "51mCSK àª¸àª¾àª®à«‡àª¨à«€ àªœà«€àª¤ àª¬àª¾àª¦ àªª...                  NaN   \n",
              "33  ABP Ananda\n",
              "@abpanandatv\n",
              "Â·\n",
              "51mà¦°à¦¾à¦œà¦¸à§à¦¥à¦¾à¦¨ à¦®à§à¦¯à¦¾à¦šà§‡à¦° ...                  NaN   \n",
              "34  Crude & Nifty Daily View\n",
              "@hemakaroonya1\n",
              "Â·\n",
              "52m1...                  NaN   \n",
              "35  Kolly Buzz\n",
              "@KollyBuzz\n",
              "Â·\n",
              "53mThe unit of Actress...                  NaN   \n",
              "36  Times Now Sports\n",
              "@timesnowsports\n",
              "Â·\n",
              "1h#MSDhoni ...                  NaN   \n",
              "37  Hindustan Times Marathi\n",
              "@htmarathi\n",
              "Â·\n",
              "1hCSK vs ...                  NaN   \n",
              "38  Sumit Mukherjee\n",
              "@Who_Sumit\n",
              "Â·\n",
              "1hMost IPL matche...                  NaN   \n",
              "39  Akash Purohit\n",
              "@earthtoakash\n",
              "Â·\n",
              "1hà¤•à¤¾à¤² à¤°à¥‡ à¤®à¥ˆà¤š à¤®à¤¾à¤¯...                    ğŸ“¸   \n",
              "40  Ruchita Jain #savesoil\n",
              "@Ruchitaamehtaa\n",
              "Â·\n",
              "1hNam...                ğŸ™ ğŸŒ¸ ğŸ™Œ   \n",
              "\n",
              "    Comments  Likes  Retweets  \n",
              "0        NaN    NaN       NaN  \n",
              "1        NaN    NaN       NaN  \n",
              "2        NaN    NaN       NaN  \n",
              "3        NaN    NaN       NaN  \n",
              "4        NaN    NaN       2.0  \n",
              "5        NaN    NaN       NaN  \n",
              "6        NaN    NaN       NaN  \n",
              "7        NaN    1.0       6.0  \n",
              "8        NaN    NaN      14.0  \n",
              "9        NaN    NaN       NaN  \n",
              "10       NaN    NaN       NaN  \n",
              "11       NaN    NaN       NaN  \n",
              "12       NaN    NaN       NaN  \n",
              "13       NaN    NaN       NaN  \n",
              "14       NaN   11.0      62.0  \n",
              "15       NaN    NaN       NaN  \n",
              "16       NaN    NaN       NaN  \n",
              "17       NaN    NaN       NaN  \n",
              "18       NaN    2.0       1.0  \n",
              "19       NaN    1.0       2.0  \n",
              "20       NaN    NaN       NaN  \n",
              "21       NaN    NaN       NaN  \n",
              "22       NaN    1.0      19.0  \n",
              "23       NaN    2.0      67.0  \n",
              "24       NaN    NaN       NaN  \n",
              "25       NaN    NaN       NaN  \n",
              "26       1.0    NaN       3.0  \n",
              "27       NaN    NaN       NaN  \n",
              "28       NaN    1.0       1.0  \n",
              "29       NaN    NaN       1.0  \n",
              "30       NaN    NaN       1.0  \n",
              "31       NaN    2.0       7.0  \n",
              "32       NaN    NaN       3.0  \n",
              "33       NaN    NaN       NaN  \n",
              "34       1.0    NaN       NaN  \n",
              "35       NaN    NaN       3.0  \n",
              "36       1.0    2.0       5.0  \n",
              "37       NaN    NaN       NaN  \n",
              "38       NaN    1.0       1.0  \n",
              "39       NaN    2.0       7.0  \n",
              "40       NaN    NaN       1.0  "
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MYdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG5k37ZxlkYM"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(analyzer=clean_text)\n",
        "x_count1 = count.fit_transform(MYdata[\"Text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE76TPUSlkYN"
      },
      "outputs": [],
      "source": [
        "x_count_df1 = pd.DataFrame(x_count1.toarray(), columns=count.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66Vw2QbFlkYN",
        "outputId": "8bf2f09c-5789-4f30-dc5d-70f049fefed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<619x36684 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 172 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
        "X_test_dtm = vect.transform(x_count_df1)\n",
        "X_test_dtm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8qFHMFmlkYO",
        "outputId": "b3746e81-165e-41a6-9f52-648f03a8d752"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
              "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham'], dtype=object)"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "clf.fit(X_train_dtm, y_train)\n",
        "y_pred = clf.predict(X_test_dtm)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU9fz0unlkYQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}